{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e5c961f-1db2-4850-b98f-43d76b17d103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "Data uploaded to: s3://sagemaker-us-east-1-059006397895/sagemaker/fine-tuning-data/Reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "# Get the default S3 bucket created by SageMaker\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/fine-tuning-data' # A folder in your S3 bucket\n",
    "\n",
    "# Upload the local CSV file to S3\n",
    "input_s3_path = sagemaker_session.upload_data(path='Reviews.csv', bucket=bucket, key_prefix=prefix)\n",
    "\n",
    "print(f\"Data uploaded to: {input_s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a5e108-342f-42bf-970b-f41a365b395f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2025-08-26-20-29-32-740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-26 20:29:37 Starting - Starting the training job...\n",
      "2025-08-26 20:29:51 Starting - Preparing the instances for training...\n",
      "2025-08-26 20:30:17 Downloading - Downloading input data......\n",
      "2025-08-26 20:31:13 Downloading - Downloading the training image......\n",
      "2025-08-26 20:32:24 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/paramiko/pkey.py:100: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/paramiko/transport.py:259: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\u001b[0m\n",
      "\u001b[34m2025-08-26 20:32:27,035 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2025-08-26 20:32:27,037 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-08-26 20:32:27,039 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-26 20:32:27,054 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2025-08-26 20:32:27,058 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2025-08-26 20:32:28,503 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.30.2 (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 113.6/113.6 kB 12.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.5.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.2.2)\u001b[0m\n",
      "\u001b[34mCollecting torch>=2.1 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading torch-2.8.0-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (30 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (3.15.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (0.24.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (24.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (6.0.1)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers==4.30.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading regex-2025.7.34-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 40.5/40.5 kB 7.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (2.32.3)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.2->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (0.4.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (4.66.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 2)) (1.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 2)) (3.5.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 3)) (2.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 3)) (2024.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.9/site-packages (from torch>=2.1->-r requirements.txt (line 4)) (4.12.2)\u001b[0m\n",
      "\u001b[34mCollecting sympy>=1.13.3 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch>=2.1->-r requirements.txt (line 4)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch>=2.1->-r requirements.txt (line 4)) (3.1.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec in /opt/conda/lib/python3.9/site-packages (from torch>=2.1->-r requirements.txt (line 4)) (2024.6.1)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-nccl-cu12==2.27.3 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting triton==3.4.0 (from torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading triton-3.4.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=40.8.0 in /opt/conda/lib/python3.9/site-packages (from triton==3.4.0->torch>=2.1->-r requirements.txt (line 4)) (71.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.9/site-packages (from triton==3.4.0->torch>=2.1->-r requirements.txt (line 4)) (6.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.1->-r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch>=2.1->-r requirements.txt (line 4)) (2.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 1)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 1)) (3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 1)) (1.26.19)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.30.2->-r requirements.txt (line 1)) (2024.7.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata->triton==3.4.0->torch>=2.1->-r requirements.txt (line 4)) (3.19.2)\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.2/7.2 MB 109.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading torch-2.8.0-cp39-cp39-manylinux_2_28_x86_64.whl (888.0 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 888.0/888.0 MB 763.3 kB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 594.3/594.3 MB 1.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.2/10.2 MB 117.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 88.0/88.0 MB 42.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 954.8/954.8 kB 88.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 706.8/706.8 MB 944.9 kB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 193.1/193.1 MB 4.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.2/1.2 MB 66.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 63.6/63.6 MB 49.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 267.5/267.5 MB 3.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 288.2/288.2 MB 3.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 287.2/287.2 MB 3.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 322.4/322.4 MB 2.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 39.3/39.3 MB 14.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 90.0/90.0 kB 723.7 kB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading triton-3.4.0-cp39-cp39-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.4 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 155.4/155.4 MB 6.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading regex-2025.7.34-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (789 kB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 789.4/789.4 kB 51.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 6.3/6.3 MB 114.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 7.8/7.8 MB 130.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\u001b[0m\n",
      "\u001b[34mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 536.2/536.2 kB 65.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, nvidia-cusparselt-cu12, mpmath, sympy, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, triton, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, transformers, nvidia-cusolver-cu12, torch\u001b[0m\n",
      "\u001b[34mAttempting uninstall: torch\u001b[0m\n",
      "\u001b[34mFound existing installation: torch 1.13.1+cpu\u001b[0m\n",
      "\u001b[34mUninstalling torch-1.13.1+cpu:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled torch-1.13.1+cpu\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mfastai 2.7.15 requires torch<2.4,>=1.10, but you have torch 2.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mtorchaudio 0.13.1+cpu requires torch==1.13.1, but you have torch 2.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mtorchdata 0.5.1 requires torch==1.13.1, but you have torch 2.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mtorchvision 0.14.1+cpu requires torch==1.13.1, but you have torch 2.8.0 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 regex-2025.7.34 sympy-1.14.0 tokenizers-0.13.3 torch-2.8.0 transformers-4.30.2 triton-3.4.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 24.1.2 -> 25.2\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2025-08-26 20:35:48,609 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-08-26 20:35:48,610 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-08-26 20:35:48,617 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-08-26 20:35:48,621 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-26 20:35:48,650 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-08-26 20:35:48,655 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-26 20:35:48,678 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2025-08-26 20:35:48,682 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-08-26 20:35:48,700 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.large\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.large\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-training-2025-08-26-20-29-32-740\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-059006397895/pytorch-training-2025-08-26-20-29-32-740/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.large\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-059006397895/pytorch-training-2025-08-26-20-29-32-740/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.large\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"pytorch-training-2025-08-26-20-29-32-740\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-059006397895/pytorch-training-2025-08-26-20-29-32-740/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python39.zip:/opt/conda/lib/python3.9:/opt/conda/lib/python3.9/lib-dynload:/opt/conda/lib/python3.9/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.9 train.py --epochs 1\u001b[0m\n",
      "\u001b[34m2025-08-26 20:35:48,768 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34mSome weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias']\u001b[0m\n",
      "\u001b[34m- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34mSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\u001b[0m\n",
      "\u001b[34mYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m0%|          | 0/12 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\u001b[0m\n",
      "\u001b[34m8%|â–Š         | 1/12 [00:06<01:10,  6.37s/it]\u001b[0m\n",
      "\u001b[34m17%|â–ˆâ–‹        | 2/12 [00:12<01:03,  6.33s/it]\u001b[0m\n",
      "\u001b[34m25%|â–ˆâ–ˆâ–Œ       | 3/12 [00:18<00:55,  6.22s/it]\u001b[0m\n",
      "\u001b[34m33%|â–ˆâ–ˆâ–ˆâ–      | 4/12 [00:24<00:49,  6.19s/it]\u001b[0m\n",
      "\u001b[34m42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 5/12 [00:31<00:43,  6.16s/it]\u001b[0m\n",
      "\u001b[34m50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 6/12 [00:37<00:36,  6.14s/it]\u001b[0m\n",
      "\u001b[34m58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 7/12 [00:43<00:30,  6.13s/it]\u001b[0m\n",
      "\u001b[34m67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 8/12 [00:49<00:24,  6.11s/it]\u001b[0m\n",
      "\u001b[34m75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 9/12 [00:55<00:18,  6.11s/it]\u001b[0m\n",
      "\u001b[34m83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 10/12 [01:01<00:12,  6.20s/it]\u001b[0m\n",
      "\u001b[34m92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 11/12 [01:07<00:06,  6.18s/it]\u001b[0m\n",
      "\u001b[34m100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [01:09<00:00,  4.86s/it]\u001b[0m\n",
      "\u001b[34m100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [01:09<00:00,  4.86s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 69.7701, 'train_samples_per_second': 2.58, 'train_steps_per_second': 0.172, 'train_loss': 0.49356238047281903, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [01:09<00:00,  5.81s/it]\u001b[0m\n",
      "\u001b[34m2025-08-26 20:37:18,568 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2025-08-26 20:37:18,569 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2025-08-26 20:37:18,569 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-08-26 20:38:44 Uploading - Uploading generated training model\n",
      "2025-08-26 20:38:44 Completed - Training job completed\n",
      "Training seconds: 507\n",
      "Billable seconds: 507\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# Get the IAM role for the notebook\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Create a PyTorch Estimator\n",
    "estimator = PyTorch(\n",
    "    entry_point='train.py',            # Your training script\n",
    "    source_dir='./source',             # The directory of your script\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',       # A powerful instance for training\n",
    "    framework_version='1.13.1',\n",
    "    py_version='py39',\n",
    "    requirements_file='./source/requirements.txt',\n",
    "    hyperparameters={'epochs': 1}\n",
    ")\n",
    "\n",
    "# Launch the training job\n",
    "estimator.fit({'train': input_s3_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17b8c835-d6f9-43cf-ae76-71976299792e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model is located at: s3://sagemaker-us-east-1-059006397895/pytorch-training-2025-08-26-20-29-32-740/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Get the S3 path of the trained model artifact (model.tar.gz)\n",
    "model_s3_path = estimator.model_data\n",
    "print(f\"Trained model is located at: {model_s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19b55c3e-3788-47c8-bed8-467c1c902eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (s3://sagemaker-us-east-1-059006397895/pytorch-training-2025-08-26-20-29-32-740/output/model.tar.gz), script artifact (./source_deploy), and dependencies ([]) into single tar.gz file located at s3://sagemaker-us-east-1-059006397895/pytorch-inference-2025-08-26-21-01-19-712/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2025-08-26-21-01-41-208\n",
      "INFO:sagemaker:Creating endpoint-config with name pytorch-inference-2025-08-26-21-01-41-724\n",
      "INFO:sagemaker:Creating endpoint with name pytorch-inference-2025-08-26-21-01-41-724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "\n",
    "# Create a SageMaker Model object from the trained artifact\n",
    "model = PyTorchModel(\n",
    "    model_data=model_s3_path,      # Path to your trained model in S3\n",
    "    role=role,                     # The same IAM role\n",
    "    entry_point='inference.py',    # Your inference script\n",
    "    source_dir='./source_deploy',  # The directory of the script\n",
    "    framework_version='1.13.1',\n",
    "    py_version='py39'\n",
    ")\n",
    "\n",
    "# Deploy the model to a real-time endpoint\n",
    "predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.t2.medium' # A small instance is fine for hosting\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ee855df-4424-4cb1-85e7-f24bb5fb4c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.7977247834205627}]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# The text you want to analyze\n",
    "test_data = {\"text\": \"This movie was absolutely fantastic, the best I have seen all year!\"}\n",
    "\n",
    "# Tell the predictor to send data as JSON\n",
    "predictor.serializer = JSONSerializer()\n",
    "\n",
    "# Tell the predictor to expect a JSON response back\n",
    "predictor.deserializer = JSONDeserializer()\n",
    "\n",
    "# Get a prediction\n",
    "response = predictor.predict(test_data)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41842f68-7772-47ea-9a5d-5d308f0274d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attached SageMaker policy to role: genmab-takehome-sagemaker-role\n",
      "Waiting for IAM policy propagation...\n",
      "Deleted existing Lambda function. Recreating...\n",
      "Lambda function created with ARN: arn:aws:lambda:us-east-1:059006397895:function:sagemaker-proxy-lambda\n",
      "API Gateway created with endpoint: https://30522nn89f.execute-api.us-east-1.amazonaws.com\n",
      "Granted API Gateway permission to invoke Lambda.\n",
      "\n",
      "ğŸ‰ Deployment Complete!\n",
      "Your API is live at: https://30522nn89f.execute-api.us-east-1.amazonaws.com/\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import time\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# Get the current execution role to reuse for Lambda\n",
    "try:\n",
    "    role_arn = sagemaker.get_execution_role()\n",
    "except NameError: # If sagemaker library is not imported, get role differently\n",
    "    iam_client = boto3.client('iam')\n",
    "    role_arn = iam_client.get_role(RoleName='AmazonSageMaker-ExecutionRole-YYYYMMDDTHHMMSS')['Role']['Arn'] # Replace with your actual role name if different\n",
    "\n",
    "# Get the SageMaker endpoint name from the previously deployed predictor\n",
    "# predictor is the variable from the last step where you ran model.deploy()\n",
    "sagemaker_endpoint_name = predictor.endpoint_name \n",
    "\n",
    "lambda_function_name = \"sagemaker-proxy-lambda\"\n",
    "api_name = \"sagemaker-proxy-api\"\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# --- 2. Create the Lambda Function Code ---\n",
    "lambda_code = f\"\"\"\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "ENDPOINT_NAME = '{sagemaker_endpoint_name}'\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    try:\n",
    "        body = json.loads(event.get(\"body\", \"{{}}\"))\n",
    "        response = sagemaker_runtime.invoke_endpoint(\n",
    "            EndpointName=ENDPOINT_NAME,\n",
    "            ContentType='application/json',\n",
    "            Body=json.dumps(body)\n",
    "        )\n",
    "        result = response['Body'].read().decode('utf-8')\n",
    "        return {{\n",
    "            'statusCode': 200,\n",
    "            'headers': {{'Content-Type': 'application/json'}},\n",
    "            'body': result\n",
    "        }}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {{'statusCode': 500, 'body': json.dumps('Error invoking endpoint.')}}\n",
    "\"\"\"\n",
    "\n",
    "# Write the code to a file\n",
    "with open(\"lambda_handler.py\", \"w\") as f:\n",
    "    f.write(lambda_code)\n",
    "\n",
    "# --- 3. Create the Deployment Package (Zip File) ---\n",
    "with zipfile.ZipFile('deployment_package.zip', 'w') as z:\n",
    "    z.write('lambda_handler.py')\n",
    "\n",
    "# --- 4. Attach the necessary SageMaker policy to the IAM role ---\n",
    "iam_client = boto3.client('iam')\n",
    "role_name = role_arn.split('/')[-1]\n",
    "sagemaker_invoke_policy_arn = \"arn:aws:iam::aws:policy/AmazonSageMakerFullAccess\" # For simplicity; a more restrictive policy is better for production\n",
    "iam_client.attach_role_policy(RoleName=role_name, PolicyArn=sagemaker_invoke_policy_arn)\n",
    "print(f\"Attached SageMaker policy to role: {role_name}\")\n",
    "# It can take a few moments for the policy to attach and propagate\n",
    "print(\"Waiting for IAM policy propagation...\")\n",
    "time.sleep(15) \n",
    "\n",
    "# --- 5. Create the Lambda Function ---\n",
    "lambda_client = boto3.client('lambda')\n",
    "\n",
    "with open('deployment_package.zip', 'rb') as f:\n",
    "    zipped_code = f.read()\n",
    "\n",
    "try:\n",
    "    # Delete the function if it already exists\n",
    "    lambda_client.delete_function(FunctionName=lambda_function_name)\n",
    "    print(\"Deleted existing Lambda function. Recreating...\")\n",
    "    time.sleep(5)\n",
    "except lambda_client.exceptions.ResourceNotFoundException:\n",
    "    pass # Function doesn't exist, which is fine\n",
    "\n",
    "lambda_response = lambda_client.create_function(\n",
    "    FunctionName=lambda_function_name,\n",
    "    Runtime='python3.9',\n",
    "    Role=role_arn,\n",
    "    Handler='lambda_handler.lambda_handler',\n",
    "    Code={'ZipFile': zipped_code},\n",
    "    Timeout=60\n",
    ")\n",
    "lambda_arn = lambda_response['FunctionArn']\n",
    "print(f\"Lambda function created with ARN: {lambda_arn}\")\n",
    "\n",
    "# --- 6. Create the API Gateway (HTTP API) ---\n",
    "apigw_client = boto3.client('apigatewayv2')\n",
    "\n",
    "try:\n",
    "    # Find and delete if it already exists\n",
    "    apis = apigw_client.get_apis()['Items']\n",
    "    for api in apis:\n",
    "        if api['Name'] == api_name:\n",
    "            apigw_client.delete_api(ApiId=api['ApiId'])\n",
    "            print(\"Deleted existing API Gateway. Recreating...\")\n",
    "            time.sleep(5)\n",
    "except Exception as e:\n",
    "    pass\n",
    "\n",
    "api_response = apigw_client.create_api(\n",
    "    Name=api_name,\n",
    "    ProtocolType='HTTP',\n",
    "    Target=lambda_arn\n",
    ")\n",
    "api_id = api_response['ApiId']\n",
    "api_endpoint = api_response['ApiEndpoint']\n",
    "print(f\"API Gateway created with endpoint: {api_endpoint}\")\n",
    "\n",
    "# --- 7. Grant API Gateway permission to invoke Lambda ---\n",
    "lambda_client.add_permission(\n",
    "    FunctionName=lambda_function_name,\n",
    "    StatementId='apigateway-invoke',\n",
    "    Action='lambda:InvokeFunction',\n",
    "    Principal='apigateway.amazonaws.com',\n",
    "    SourceArn=f\"arn:aws:execute-api:{region}:{boto3.client('sts').get_caller_identity()['Account']}:{api_id}/*/*\"\n",
    ")\n",
    "print(\"Granted API Gateway permission to invoke Lambda.\")\n",
    "\n",
    "print(\"\\nğŸ‰ Deployment Complete!\")\n",
    "print(f\"Your API is live at: {api_endpoint}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a58d0d-4e05-479d-89f7-b1949da2eea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Clean Up Script ---\n",
    "# print(\"Starting cleanup...\")\n",
    "# try:\n",
    "#     # Delete API Gateway\n",
    "#     apis = apigw_client.get_apis()['Items']\n",
    "#     for api in apis:\n",
    "#         if api['Name'] == api_name:\n",
    "#             apigw_client.delete_api(ApiId=api['ApiId'])\n",
    "#             print(f\"Deleted API Gateway: {api_name}\")\n",
    "#             break\n",
    "            \n",
    "#     # Delete Lambda Function\n",
    "#     lambda_client.delete_function(FunctionName=lambda_function_name)\n",
    "#     print(f\"Deleted Lambda function: {lambda_function_name}\")\n",
    "    \n",
    "#     # Detach policy from role\n",
    "#     iam_client.detach_role_policy(RoleName=role_name, PolicyArn=sagemaker_invoke_policy_arn)\n",
    "#     print(f\"Detached SageMaker policy from role: {role_name}\")\n",
    "    \n",
    "#     # Don't forget to delete your SageMaker endpoint if you haven't already!\n",
    "#     predictor.delete_endpoint()\n",
    "\n",
    "#     print(\"\\nâœ… Cleanup complete.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"An error occurred during cleanup: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
